# Comprehensive Comparative Study of Linear and Nonlinear Dimensionality Reduction Techniques

## Project Overview
This project systematically compares classical linear and modern nonlinear dimensionality reduction (DR) techniques across diverse datasets. It evaluates methods based on visualization quality, downstream classification performance, reconstruction error, and computational efficiency to provide practical guidance for data scientists.

---

## Team Details
- **Monika** – SRN: PES1UG23AM174  
- **Krithika K** – SRN: PES1UG23AM150  

---

## Objectives
1. Gain hands-on experience in implementing linear and nonlinear DR techniques.  
2. Analyze their impact on classification tasks across multiple datasets.  
3. Provide insights for selecting appropriate DR methods for different data types.

---

## Datasets
The project uses the following datasets (download links or from scikit-learn/Keras):  
- **Text**: 20 Newsgroups (TF-IDF)  
- **Graph**: cora  
- **Signals/Audio**: Speech Commands
- **Time Series**: UCI HAR dataset  
- **Genomic**: PBMC 3k  

> **Note:** datasets source are included in ppt to avoid uploading huge files to GitHub.

---

## Dimensionality Reduction Methods
### Linear Methods
- PCA (Principal Component Analysis)  
- LDA (Linear Discriminant Analysis)  
- ICA (Independent Component Analysis)  
- Non-negative Matrix Factorization (NMF)  

### Nonlinear Methods
- t-SNE  
- UMAP  
- Autoencoders  

---

## Classification Models
- Logistic Regression  
- Support Vector Machine (SVM)  
- k-Nearest Neighbors (kNN)  


---

## Evaluation Metrics
- Reconstruction Error  
- Visualization Quality (2D scatter plots)  
- Accuracy,  F1-Score   
- Computation Time
- Clustering Metrics (Genomic and Graph Datasets)•	Silhouette Score,•	Calinski–Harabasz Index,•	Davies–Bouldin Index

---

## How to Run
1. Clone the repository:
   ```bash
   git clone https://github.com/Krithikakannan/AFML_150_174.git
